---
page_title: "spectrocloud_backup_storage_location Resource - terraform-provider-spectrocloud"
subcategory: ""
description: |-
  
---

# spectrocloud_backup_storage_location (Resource)

  

## Example Usage


```terraform
resource "spectrocloud_backup_storage_location" "bsl1" {
  name        = "dev-backup-s3"
  context     = "tenant"
  is_default  = false
  region      = "us-east-2"
  bucket_name = "dev-backup"
  s3 {
    credential_type     = var.credential_type
    access_key          = var.aws_access_key
    secret_key          = var.aws_secret_key
    s3_force_path_style = false

    #s3_url             = "http://10.90.78.23"
  }
}

resource "spectrocloud_backup_storage_location" "bsl2" {
  name        = "prod-backup-s3"
  is_default  = false
  region      = "us-east-2"
  bucket_name = "prod-backup"
  s3 {
    credential_type     = var.credential_type
    arn                 = var.arn
    external_id         = var.external_id
    s3_force_path_style = false
    #s3_url             = "http://10.90.78.23"
  }
}
```

## Import

Backup Storage Locations can be imported using either a simple ID format or with explicit context specification. This resource supports both project and tenant contexts.

### Simple Import (defaults to project context)

```bash
terraform import spectrocloud_backup_storage_location.example <bsl_id>:project
```

### Context-specific Import

```bash
terraform import spectrocloud_backup_storage_location.example <bsl_id>:project
terraform import spectrocloud_backup_storage_location.example <bsl_id>:tenant
```

Where:
- `<bsl_id>` is the Backup Storage Location ID
- `project` or `tenant` specifies the context where the backup storage location exists

**Import behavior:**
- If no context is specified, it defaults to `project` context
- If the resource is not found in the specified context, the import will automatically try the other context
- The import will automatically populate all configuration fields from the Spectro Cloud API, including the correct context, storage provider, and all provider-specific settings

After import, you can run `terraform plan` to see the current configuration and make any necessary adjustments.


<!-- schema generated by tfplugindocs -->
## Schema

### Required

- `name` (String) The name of the backup storage location. This is a unique identifier for the backup location.

### Optional

- `azure_storage_config` (Block List, Max: 1) Azure storage settings for configuring the backup storage location. (see [below for nested schema](#nestedblock--azure_storage_config))
- `bucket_name` (String) The name of the storage bucket where backups are stored. This is relevant for S3 or S3-compatible(minio) or gcp storage services.
- `ca_cert` (String) An optional CA certificate used for SSL connections to ensure secure communication with the storage provider. This is relevant for S3 or S3-compatible(minio) storage services.
- `context` (String) The context of the backup storage location. Allowed values are `project` or `tenant`. Default value is `project`. If  the `project` context is specified, the project name will sourced from the provider configuration parameter [`project_name`](https://registry.terraform.io/providers/spectrocloud/spectrocloud/latest/docs#schema).
- `gcp_storage_config` (Block List, Max: 1) GCP storage settings for configuring the backup storage location. (see [below for nested schema](#nestedblock--gcp_storage_config))
- `is_default` (Boolean) Specifies if this backup storage location should be used as the default location for storing backups.
- `region` (String) The region where the backup storage is located, typically corresponding to the region of the cloud provider. This is relevant for S3 or S3-compatible(minio) storage services.
- `s3` (Block List, Max: 1) S3-specific settings for configuring the backup storage location. (see [below for nested schema](#nestedblock--s3))
- `storage_provider` (String) The storage location provider for backup storage. Allowed values are `aws` or `minio` or `gcp` or `azure`. Default value is `aws`.
- `timeouts` (Block, Optional) (see [below for nested schema](#nestedblock--timeouts))

### Read-Only

- `id` (String) The ID of this resource.

<a id="nestedblock--azure_storage_config"></a>
### Nested Schema for `azure_storage_config`

Required:

- `azure_client_id` (String) Unique client Id from Azure console.
- `azure_client_secret` (String, Sensitive) Azure secret for authentication.
- `azure_tenant_id` (String) Unique tenant Id from Azure console.
- `container_name` (String) The container name.
- `resource_group` (String) The resource group name.
- `stock_keeping_unit` (String) The stop-keeping unit. eg: `Standard_LRS`
- `storage_name` (String) The storage name.
- `subscription_id` (String) Unique subscription Id from Azure console.


<a id="nestedblock--gcp_storage_config"></a>
### Nested Schema for `gcp_storage_config`

Required:

- `gcp_json_credentials` (String, Sensitive) The GCP credentials in JSON format. These credentials are required to authenticate and manage.
- `project_id` (String) The GCP project ID.


<a id="nestedblock--s3"></a>
### Nested Schema for `s3`

Required:

- `credential_type` (String) The type of credentials used to access the S3 storage. Supported values are 'secret' for static credentials and 'sts' for temporary, token-based credentials.

Optional:

- `access_key` (String) The access key for S3 authentication, required if 'credential_type' is set to 'secret'.
- `arn` (String) The Amazon Resource Name (ARN) of the IAM role to assume for accessing S3 when using 'sts' credentials.
- `external_id` (String) An external ID used for cross-account access to the S3 storage when using 'sts' credentials.
- `s3_force_path_style` (Boolean) A boolean flag indicating whether to enforce the path-style URL for accessing S3.
- `s3_url` (String) The S3 URL endpoint.
- `secret_key` (String) The secret key for S3 authentication, required if 'credential_type' is set to 'secret'.


<a id="nestedblock--timeouts"></a>
### Nested Schema for `timeouts`

Optional:

- `create` (String)
- `delete` (String)
- `update` (String)